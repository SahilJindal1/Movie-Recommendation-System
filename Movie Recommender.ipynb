{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f46ee9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import col, mean, udf, lit, current_timestamp, unix_timestamp, array_contains\n",
    "\n",
    "import pandas as pd\n",
    "import math\n",
    "import mlflow\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2976532b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/04 03:34:06 WARN Utils: Your hostname, avani-HP resolves to a loopback address: 127.0.1.1; using 192.168.0.9 instead (on interface wlo1)\n",
      "22/12/04 03:34:06 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "22/12/04 03:34:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "# instantiate the Spark session\n",
    "\n",
    "from pyspark.conf import SparkConf\n",
    "\n",
    "sparkConf = SparkConf()\n",
    "sparkConf.setAppName(\"My app\").set(\"spark.jars\", \"/home/avani/UMass/Fall 2022/CS 532/Project/postgresql-42.5.0.jar\")\n",
    "sparkConf.set(\"spark.dynamicAllocation.enabled\", \"true\")\n",
    "sparkConf.set(\"spark.executor.cores\", 8)\n",
    "sparkConf.set(\"spark.dynamicAllocation.minExecutors\",\"1\")\n",
    "sparkConf.set(\"spark.dynamicAllocation.maxExecutors\",\"5000\")\n",
    "sparkConf.set(\"spark.executor.memory\", \"32g\")\n",
    "sparkConf.set(\"spark.ui.port\",\"4050\")\n",
    "sparkConf.set(\"spark.memory.fraction\", 0.7)\n",
    "\n",
    "spark = SparkSession.builder.master('local[*]').config(conf=sparkConf).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80779474",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "In case you want to try running, you can read from csv files directly and skip the next 3 cells.\n",
    "'''\n",
    "\n",
    "# movies_df = spark.read.load(\"/home/avani/UMass/Fall 2022/CS 532/Project/ml-latest/movies.csv\", format='csv', header = True)\n",
    "# ratings_df = spark.read.load(\"/home/avani/UMass/Fall 2022/CS 532/Project/ml-latest/ratings.csv\", format='csv', header = True)\n",
    "# links_df = spark.read.load(\"/home/avani/UMass/Fall 2022/CS 532/Project/ml-latest/links.csv\", format='csv', header = True)\n",
    "# tags_df = spark.read.load(\"/home/avani/UMass/Fall 2022/CS 532/Project/ml-latest/tags.csv\", format='csv', header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb434531",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables_list = ['movies', 'ratings', 'tags', 'links']\n",
    "\n",
    "dataframeList = {}\n",
    "\n",
    "# read each table \n",
    "for table in tables_list:\n",
    "\n",
    "    # parameters specified for ratings table\n",
    "    if table == 'ratings':\n",
    "        dataframeList[table] = spark.read.format(\"jdbc\"). \\\n",
    "                                options(\n",
    "                                 url = 'jdbc:postgresql://localhost:5432/movielens_dataset', # using jdbc:postgresql://<host>:<port>/<database>\n",
    "                                 dbtable = table + \"_new\",\n",
    "                                 user = 'postgres',\n",
    "                                 password = 'postgres',\n",
    "                                 driver = 'org.postgresql.Driver',\n",
    "                                 fetchSize = 1000,\n",
    "                                 partitionColumn = \"userId\",\n",
    "                                 lowerBound = 1,\n",
    "                                 upperBound = 283228,\n",
    "                                 numPartitions = 32).\\\n",
    "                                load()\n",
    "    else:\n",
    "        dataframeList[table] = spark.read.format(\"jdbc\"). \\\n",
    "                                options(\n",
    "                                 url = 'jdbc:postgresql://localhost:5432/movielens_dataset', # using jdbc:postgresql://<host>:<port>/<database>\n",
    "                                 dbtable = table + \"_new\",\n",
    "                                 user = 'postgres',\n",
    "                                 password = 'postgres',\n",
    "                                 driver = 'org.postgresql.Driver').\\\n",
    "                                load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b29c34c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movies table\n",
      "root\n",
      " |-- movieid: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      "\n",
      "None\n",
      "ratings table\n",
      "root\n",
      " |-- userid: integer (nullable = true)\n",
      " |-- movieid: integer (nullable = true)\n",
      " |-- rating: decimal(38,18) (nullable = true)\n",
      " |-- timestamp: integer (nullable = true)\n",
      "\n",
      "None\n",
      "tags table\n",
      "root\n",
      " |-- userid: integer (nullable = true)\n",
      " |-- movieid: integer (nullable = true)\n",
      " |-- tag: string (nullable = true)\n",
      " |-- timestamp: integer (nullable = true)\n",
      "\n",
      "None\n",
      "links table\n",
      "root\n",
      " |-- movieid: integer (nullable = true)\n",
      " |-- imdbid: integer (nullable = true)\n",
      " |-- tmdbid: integer (nullable = true)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for key, value in dataframeList.items():\n",
    "    print(key + \" table\")\n",
    "    print(value.printSchema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "885f9647",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = dataframeList['movies']\n",
    "ratings_df = dataframeList['ratings']\n",
    "links_df = dataframeList['links']\n",
    "tags_df = dataframeList['tags']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89930d87",
   "metadata": {},
   "source": [
    "### Show the dataframes and make the lifetime of dataframes same as spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "461c67fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+\n",
      "|movieid|               title|              genres|\n",
      "+-------+--------------------+--------------------+\n",
      "|      1|    Toy Story (1995)|Adventure|Animati...|\n",
      "|      2|      Jumanji (1995)|Adventure|Childre...|\n",
      "|      3|Grumpier Old Men ...|      Comedy|Romance|\n",
      "|      4|Waiting to Exhale...|Comedy|Drama|Romance|\n",
      "|      5|Father of the Bri...|              Comedy|\n",
      "|      6|         Heat (1995)|Action|Crime|Thri...|\n",
      "|      7|      Sabrina (1995)|      Comedy|Romance|\n",
      "|      8| Tom and Huck (1995)|  Adventure|Children|\n",
      "|      9| Sudden Death (1995)|              Action|\n",
      "|     10|    GoldenEye (1995)|Action|Adventure|...|\n",
      "|     11|American Presiden...|Comedy|Drama|Romance|\n",
      "|     12|Dracula: Dead and...|       Comedy|Horror|\n",
      "|     13|        Balto (1995)|Adventure|Animati...|\n",
      "|     14|        Nixon (1995)|               Drama|\n",
      "|     15|Cutthroat Island ...|Action|Adventure|...|\n",
      "|     16|       Casino (1995)|         Crime|Drama|\n",
      "|     17|Sense and Sensibi...|       Drama|Romance|\n",
      "|     18|   Four Rooms (1995)|              Comedy|\n",
      "|     19|Ace Ventura: When...|              Comedy|\n",
      "|     20|  Money Train (1995)|Action|Comedy|Cri...|\n",
      "+-------+--------------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "movies_df.createOrReplaceTempView(\"movies_df\")\n",
    "spark.sql(\"SELECT * FROM movies_df limit 20\").show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d927abde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 3:===================================>                     (20 + 8) / 32]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+--------------------+---------+\n",
      "|userid|movieid|              rating|timestamp|\n",
      "+------+-------+--------------------+---------+\n",
      "|     1|      1|4.000000000000000000|964982703|\n",
      "|     1|      3|4.000000000000000000|964981247|\n",
      "|     1|      6|4.000000000000000000|964982224|\n",
      "|     1|     47|5.000000000000000000|964983815|\n",
      "|     1|     50|5.000000000000000000|964982931|\n",
      "|     1|     70|3.000000000000000000|964982400|\n",
      "|     1|    101|5.000000000000000000|964980868|\n",
      "|     1|    110|4.000000000000000000|964982176|\n",
      "|     1|    151|5.000000000000000000|964984041|\n",
      "|     1|    157|5.000000000000000000|964984100|\n",
      "|     1|    163|5.000000000000000000|964983650|\n",
      "|     1|    216|5.000000000000000000|964981208|\n",
      "|     1|    223|3.000000000000000000|964980985|\n",
      "|     1|    231|5.000000000000000000|964981179|\n",
      "|     1|    235|4.000000000000000000|964980908|\n",
      "|     1|    260|5.000000000000000000|964981680|\n",
      "|     1|    296|3.000000000000000000|964982967|\n",
      "|     1|    316|3.000000000000000000|964982310|\n",
      "|     1|    333|5.000000000000000000|964981179|\n",
      "|     1|    349|4.000000000000000000|964982563|\n",
      "+------+-------+--------------------+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "ratings_df.createOrReplaceTempView(\"ratings_df\")\n",
    "spark.sql(\"SELECT * FROM ratings_df limit 20\").show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7269a5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------+\n",
      "|movieid|imdbid|tmdbid|\n",
      "+-------+------+------+\n",
      "|      1|114709|   862|\n",
      "|      2|113497|  8844|\n",
      "|      3|113228| 15602|\n",
      "|      4|114885| 31357|\n",
      "|      5|113041| 11862|\n",
      "|      6|113277|   949|\n",
      "|      7|114319| 11860|\n",
      "|      8|112302| 45325|\n",
      "|      9|114576|  9091|\n",
      "|     10|113189|   710|\n",
      "|     11|112346|  9087|\n",
      "|     12|112896| 12110|\n",
      "|     13|112453| 21032|\n",
      "|     14|113987| 10858|\n",
      "|     15|112760|  1408|\n",
      "|     16|112641|   524|\n",
      "|     17|114388|  4584|\n",
      "|     18|113101|     5|\n",
      "|     19|112281|  9273|\n",
      "|     20|113845| 11517|\n",
      "+-------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "links_df.createOrReplaceTempView(\"links_df\")\n",
    "spark.sql(\"SELECT * FROM links_df limit 20\").show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b31ab98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+-----------------+----------+\n",
      "|userid|movieid|              tag| timestamp|\n",
      "+------+-------+-----------------+----------+\n",
      "|     2|  60756|            funny|1445714994|\n",
      "|     2|  60756|  Highly quotable|1445714996|\n",
      "|     2|  60756|     will ferrell|1445714992|\n",
      "|     2|  89774|     Boxing story|1445715207|\n",
      "|     2|  89774|              MMA|1445715200|\n",
      "|     2|  89774|        Tom Hardy|1445715205|\n",
      "|     2| 106782|            drugs|1445715054|\n",
      "|     2| 106782|Leonardo DiCaprio|1445715051|\n",
      "|     2| 106782|  Martin Scorsese|1445715056|\n",
      "|     7|  48516|     way too long|1169687325|\n",
      "|    18|    431|        Al Pacino|1462138765|\n",
      "|    18|    431|         gangster|1462138749|\n",
      "|    18|    431|            mafia|1462138755|\n",
      "|    18|   1221|        Al Pacino|1461699306|\n",
      "|    18|   1221|            Mafia|1461699303|\n",
      "|    18|   5995|        holocaust|1455735472|\n",
      "|    18|   5995|       true story|1455735479|\n",
      "|    18|  44665|     twist ending|1456948283|\n",
      "|    18|  52604|  Anthony Hopkins|1457650696|\n",
      "|    18|  52604|  courtroom drama|1457650711|\n",
      "+------+-------+-----------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tags_df.createOrReplaceTempView(\"tags_df\")\n",
    "spark.sql(\"SELECT * FROM tags_df limit 20\").show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d386f6e1",
   "metadata": {},
   "source": [
    "### Registering the dataframes to spark "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85adb7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avani/.local/lib/python3.10/site-packages/pyspark/sql/dataframe.py:229: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "movies_df.registerTempTable(\"movies\")\n",
    "ratings_df.registerTempTable(\"ratings\")\n",
    "links_df.registerTempTable(\"links\")\n",
    "tags_df.registerTempTable(\"tags\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ee103c",
   "metadata": {},
   "source": [
    "### Analyse the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae75c29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum number of ratings per user: 20\n",
      "Minimum number of ratings per movie: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 15:==================================================>     (29 + 3) / 32]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "minRating_1 = ratings_df.groupBy(\"userID\").count().toPandas()['count'].min()\n",
    "minRating_2 = ratings_df.groupBy(\"movieId\").count().toPandas()['count'].min()\n",
    "\n",
    "print('Minimum number of ratings per user: {}'.format(minRating_1))\n",
    "print('Minimum number of ratings per movie: {}'.format(minRating_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e27d73b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movies are rated by only one user: 3446 out of 9724 \n"
     ]
    }
   ],
   "source": [
    "_rating1 = sum(ratings_df.groupBy(\"movieId\").count().toPandas()['count'] == 1)\n",
    "_total = ratings_df.select('movieId').distinct().count()\n",
    "\n",
    "print('movies are rated by only one user: {} out of {} '.format(_rating1, _total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cd8195f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 27:===========================================>            (25 + 7) / 32]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "610"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of distinct users\n",
    "num_users = spark.sql(\"SELECT count (distinct userID) as num_users FROM ratings\")\n",
    "ratings_df.select(\"userId\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "175af2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9742\n"
     ]
    }
   ],
   "source": [
    "# number of movies\n",
    "num_movies = spark.sql(\"SELECT count (distinct movieID) as num_movies FROM movies\")\n",
    "print(movies_df.select('movieID').distinct().count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0adf4671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of movies rated by users: 9724\n"
     ]
    }
   ],
   "source": [
    "rated_by_users = ratings_df.select('movieID').distinct().count()\n",
    "print('Total Number of movies rated by users:', rated_by_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "490de7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 46:===============================================>        (27 + 5) / 32]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------+\n",
      "|               title|              genres|rating|\n",
      "+--------------------+--------------------+------+\n",
      "|Color of Paradise...|               Drama|  null|\n",
      "|      Niagara (1953)|      Drama|Thriller|  null|\n",
      "|        Proof (1991)|Comedy|Drama|Romance|  null|\n",
      "|Road Home, The (W...|       Drama|Romance|  null|\n",
      "|Parallax View, Th...|            Thriller|  null|\n",
      "|Mutiny on the Bou...|Adventure|Drama|R...|  null|\n",
      "|Browning Version,...|               Drama|  null|\n",
      "|Twentieth Century...|              Comedy|  null|\n",
      "|In the Realms of ...|Animation|Documen...|  null|\n",
      "|      Scrooge (1970)|Drama|Fantasy|Mus...|  null|\n",
      "+--------------------+--------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# null rated movies\n",
    "spark.sql(\"SELECT movies.title, movies.genres ,ratings.rating FROM movies left JOIN ratings ON ratings.movieId = movies.movieID WHERE ratings.rating IS null LIMIT 10\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d0a78ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|              genres|\n",
      "+--------------------+\n",
      "|Comedy|Horror|Thr...|\n",
      "|Adventure|Sci-Fi|...|\n",
      "|Action|Adventure|...|\n",
      "| Action|Drama|Horror|\n",
      "|Action|Animation|...|\n",
      "|Animation|Childre...|\n",
      "|Action|Adventure|...|\n",
      "|    Adventure|Sci-Fi|\n",
      "|Documentary|Music...|\n",
      "|Adventure|Childre...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# movie genres\n",
    "spark.sql(\"SELECT DISTINCT(genres) FROM movies LIMIT 10\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c79f9698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[movieId: int, title: string, genres: array<string>]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "extract_genres = udf(lambda x: x.split(\"|\"), ArrayType(StringType()))\n",
    "movies_df_clean = movies_df.select(\"movieId\", \"title\", extract_genres(\"genres\").alias(\"genres\"))\n",
    "\n",
    "movies_df_clean.createOrReplaceTempView(\"movies_df_clean\")\n",
    "\n",
    "display (spark.sql(\"SELECT * FROM movies_df_clean limit 5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "83c70eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 57:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+\n",
      "|movieId|               title|              genres|\n",
      "+-------+--------------------+--------------------+\n",
      "|      1|    Toy Story (1995)|[Adventure, Anima...|\n",
      "|      2|      Jumanji (1995)|[Adventure, Child...|\n",
      "|      3|Grumpier Old Men ...|   [Comedy, Romance]|\n",
      "|      4|Waiting to Exhale...|[Comedy, Drama, R...|\n",
      "|      5|Father of the Bri...|            [Comedy]|\n",
      "+-------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "movies_df_clean.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5549a27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Comedy',\n",
       " 'Adventure',\n",
       " 'Mystery',\n",
       " 'Musical',\n",
       " 'Sci-Fi',\n",
       " 'War',\n",
       " 'Crime',\n",
       " 'Western',\n",
       " '(no genres listed)',\n",
       " 'Children',\n",
       " 'Documentary',\n",
       " 'Horror',\n",
       " 'Film-Noir',\n",
       " 'Fantasy',\n",
       " 'Drama',\n",
       " 'Romance',\n",
       " 'Action',\n",
       " 'IMAX',\n",
       " 'Animation',\n",
       " 'Thriller']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All movie categories\n",
    "genres_result = list(set(movies_df_clean.select('genres').rdd.flatMap(tuple).flatMap(tuple).collect()))\n",
    "genres_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "733e9135",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_pdf = movies_df.toPandas()\n",
    "list_of_movie = list(movie_pdf['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469c1010",
   "metadata": {},
   "source": [
    "## Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78a2975e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data type convert\n",
    "movie_ratings = ratings_df.drop('timestamp')\n",
    "\n",
    "movie_ratings = movie_ratings.withColumn(\"userId\", movie_ratings[\"userId\"].cast(IntegerType()))\n",
    "movie_ratings = movie_ratings.withColumn(\"movieId\", movie_ratings[\"movieId\"].cast(IntegerType()))\n",
    "movie_ratings = movie_ratings.withColumn(\"rating\", movie_ratings[\"rating\"].cast(FloatType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2daab5b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+\n",
      "|userId|movieId|rating|\n",
      "+------+-------+------+\n",
      "|     1|      1|   4.0|\n",
      "|     1|      3|   4.0|\n",
      "|     1|      6|   4.0|\n",
      "|     1|     47|   5.0|\n",
      "|     1|     50|   5.0|\n",
      "|     1|     70|   3.0|\n",
      "|     1|    101|   5.0|\n",
      "|     1|    110|   4.0|\n",
      "|     1|    151|   5.0|\n",
      "|     1|    157|   5.0|\n",
      "|     1|    163|   5.0|\n",
      "|     1|    216|   5.0|\n",
      "|     1|    223|   3.0|\n",
      "|     1|    231|   5.0|\n",
      "|     1|    235|   4.0|\n",
      "|     1|    260|   5.0|\n",
      "|     1|    296|   3.0|\n",
      "|     1|    316|   3.0|\n",
      "|     1|    333|   5.0|\n",
      "|     1|    349|   4.0|\n",
      "+------+-------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[userId: int, movieId: int, rating: float]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "movie_ratings.show(20)\n",
    "movie_ratings.createOrReplaceTempView(\"movie_ratings\")\n",
    "display (spark.sql(\"SELECT * FROM movie_ratings limit 10\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bf767010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+\n",
      "|userId|movieId|rating|\n",
      "+------+-------+------+\n",
      "|     5|    253|   3.0|\n",
      "|    18|   7153|   4.5|\n",
      "|    19|    366|   2.0|\n",
      "|    32|    529|   4.0|\n",
      "|    32|   1393|   4.0|\n",
      "|    41|   6287|   5.0|\n",
      "|    42|    780|   2.0|\n",
      "|    42|   2997|   4.0|\n",
      "|    47|  53894|   3.5|\n",
      "|    51|   2133|   3.5|\n",
      "|    57|   2640|   4.0|\n",
      "|    57|   2797|   3.0|\n",
      "|    58|    440|   4.0|\n",
      "|    61|    173|   3.0|\n",
      "|    61|   1214|   4.5|\n",
      "|    62|  51540|   4.5|\n",
      "|    63|    231|   3.0|\n",
      "|    64|    223|   3.0|\n",
      "|    64|   1258|   3.5|\n",
      "|    68|    531|   2.5|\n",
      "+------+-------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movie_rating_sample = movie_ratings.sample(False, 1/500)\n",
    "movie_rating_sample.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "68bf1617",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS, ALSModel\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4ac0d674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ALS model\n",
    "als = ALS(\n",
    "         userCol=\"userId\", \n",
    "         itemCol=\"movieId\",\n",
    "         ratingCol=\"rating\", \n",
    "         nonnegative = True, \n",
    "         implicitPrefs = False,\n",
    "         coldStartStrategy=\"drop\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ebbd91e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data\n",
    "(trainData, testData) = movie_ratings.randomSplit([0.8,0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5bc84d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create parameter grid\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "            .addGrid(als.rank, [10, 50, 100, 150]) \\\n",
    "            .addGrid(als.regParam, [.01, .05, .1, .15]) \\\n",
    "            .addGrid(als.maxIter, [15]) \\\n",
    "            .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "447b6328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num models to be tested:  16\n"
     ]
    }
   ],
   "source": [
    "evaluator = RegressionEvaluator(\n",
    "               metricName=\"rmse\", \n",
    "               labelCol=\"rating\", \n",
    "               predictionCol=\"prediction\")\n",
    "\n",
    "print (\"Num models to be tested: \", len(paramGrid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5c662b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build cross validation using CrossValidator\n",
    "cv = CrossValidator(estimator=als, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "91889af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing model found!\n",
      "Loading...\n",
      "RMS Error = 0.8719822097589555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 13631:===================================================> (31 + 1) / 32]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# if model exists, use that\n",
    "if os.path.exists(\"bestALSModel\"):\n",
    "    print(\"Existing model found!\")\n",
    "    print(\"Loading...\")\n",
    "    bestALSModel = ALSModel.load('bestALSModel')\n",
    "\n",
    "# else start training    \n",
    "else:\n",
    "    print(\"Existing model not found :(\")\n",
    "    print(\"Starting training...\")\n",
    "    cvModel = cv.fit(trainData)\n",
    "    bestALSModel = cvModel.bestModel\n",
    "    \n",
    "# Getting the best model and its RMS Error\n",
    "testPredictions = bestALSModel.transform(testData)\n",
    "rmse = evaluator.evaluate(testPredictions)\n",
    "print(\"RMS Error =\",rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "835de6e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Parameters\n",
      "Rank:  50\n",
      "MaxIter:  15\n",
      "RegParam: 0.15\n"
     ]
    }
   ],
   "source": [
    "print (\"Best Model Parameters\")\n",
    "print (\"Rank: \", bestALSModel._java_obj.parent().getRank())\n",
    "print (\"MaxIter: \", str(bestALSModel._java_obj.parent().getMaxIter()))\n",
    "print (\"RegParam:\",  bestALSModel._java_obj.parent().getRegParam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a3acbca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12416:>                                                     (0 + 8) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/04 04:00:17 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "22/12/04 04:00:17 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 84.47% for 8 writers\n",
      "22/12/04 04:00:18 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/04 04:00:18 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "22/12/04 04:00:18 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 84.47% for 8 writers\n",
      "22/12/04 04:00:18 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n"
     ]
    }
   ],
   "source": [
    "# Write model to disk\n",
    "\n",
    "if not os.path.exists(\"bestALSModel\"):\n",
    "    bestALSModel.write().save(\"bestALSModel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b38c5b7",
   "metadata": {},
   "source": [
    "### Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a66a9385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating|prediction|\n",
      "+------+-------+------+----------+\n",
      "|   463|   1088|   3.5| 3.2851524|\n",
      "|   580|  44022|   3.5| 3.2771707|\n",
      "|   597|    471|   2.0| 3.8366563|\n",
      "|   597|   1580|   3.0|  3.569401|\n",
      "|   368|   1580|   3.0|  2.927928|\n",
      "|   368|   2366|   4.0| 3.1160734|\n",
      "|   368|   3918|   2.0| 2.6714442|\n",
      "|    28|   3175|   1.5| 2.8194048|\n",
      "|   587|   3175|   5.0| 3.8273165|\n",
      "|   332|   2366|   3.5| 3.4877331|\n",
      "+------+-------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test Set Predictions \n",
    "testPredictions.createOrReplaceTempView(\"predictions\")\n",
    "spark.sql(\"SELECT * FROM predictions limit 10\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "665e78b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 13635:===================================================> (31 + 1) / 32]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error is 0.6646496588537723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data = bestALSModel.transform(movie_ratings)\n",
    "rmse = evaluator.evaluate(data)\n",
    "print (\"Error is\",rmse)\n",
    "data.registerTempTable(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "febd56fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12644:===========================================>        (84 + 8) / 100]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|userId|     recommendations|\n",
      "+------+--------------------+\n",
      "|     1|[{170355, 5.78263...|\n",
      "|     3|[{6835, 4.851414}...|\n",
      "|     5|[{8477, 4.868637}...|\n",
      "|     6|[{6732, 4.8381457...|\n",
      "|     9|[{8477, 4.7684717...|\n",
      "|    12|[{5867, 5.6364326...|\n",
      "|    13|[{170355, 4.92563...|\n",
      "|    15|[{7842, 4.493137}...|\n",
      "|    16|[{96004, 4.505365...|\n",
      "|    17|[{96004, 5.162398...|\n",
      "+------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "Top10Recs = bestALSModel.recommendForAllUsers(10)\n",
    "Top10Recs.createOrReplaceTempView(\"Top10Recs\")\n",
    "spark.sql(\"SELECT * FROM Top10Recs limit 10\").show()\n",
    "Top10Recs.registerTempTable(\"Top_10_Recommendations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "36763fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+\n",
      "|userId|           MovieRec|\n",
      "+------+-------------------+\n",
      "|     1|{170355, 5.7826343}|\n",
      "|     1| {96004, 5.7826343}|\n",
      "|     1|  {3379, 5.7826343}|\n",
      "|     1|  {33649, 5.654786}|\n",
      "|     1| {132333, 5.572264}|\n",
      "|     1|   {5490, 5.572264}|\n",
      "|     1|  {7842, 5.5654945}|\n",
      "|     1|{171495, 5.5202937}|\n",
      "|     1| {78836, 5.4555316}|\n",
      "|     1| {117531, 5.451997}|\n",
      "+------+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12854:=============================================>      (87 + 8) / 100]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+----------+\n",
      "|userId|movieId|prediction|\n",
      "+------+-------+----------+\n",
      "|     1| 170355| 5.7826343|\n",
      "|     1|  96004| 5.7826343|\n",
      "|     1|   3379| 5.7826343|\n",
      "|     1|  33649|  5.654786|\n",
      "|     1| 132333|  5.572264|\n",
      "|     1|   5490|  5.572264|\n",
      "|     1|   7842| 5.5654945|\n",
      "|     1| 171495| 5.5202937|\n",
      "|     1|  78836| 5.4555316|\n",
      "|     1| 117531|  5.451997|\n",
      "+------+-------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# separate the value of 'recommendations'\n",
    "unwrapRecommendations = spark.sql('SELECT userId, explode(recommendations) AS MovieRec FROM Top_10_Recommendations')\n",
    "unwrapRecommendations.createOrReplaceTempView(\"unwrapRecs\")\n",
    "spark.sql(\"SELECT * FROM unwrapRecs limit 10\").show()\n",
    "finalRecommendations = spark.sql(\"SELECT userId,movieIds_and_ratings.movieId AS movieId,\\\n",
    "                        movieIds_and_ratings.rating AS prediction\\\n",
    "                        FROM Top_10_Recommendations\\\n",
    "                        LATERAL VIEW explode(recommendations) exploded_table AS movieIds_and_ratings\")\n",
    "finalRecommendations.createOrReplaceTempView(\"Recommendations\")\n",
    "spark.sql(\"SELECT * FROM Recommendations limit 10\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a58527",
   "metadata": {},
   "source": [
    "### Prediction of Users who haven't seen the Movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "da85b7da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12960:==================================>                  (21 + 8) / 32]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+----------+------+\n",
      "|userId|movieId|prediction|rating|\n",
      "+------+-------+----------+------+\n",
      "|     9|   4495| 4.6397157|  null|\n",
      "|   120|   3379|  4.609119|  null|\n",
      "|   133| 177593| 3.6991415|  null|\n",
      "|   137| 132333| 4.5028896|  null|\n",
      "|   218|  96004|  4.610119|  null|\n",
      "|   309|   7842| 4.4007373|  null|\n",
      "|   367|   6732| 5.0505524|  null|\n",
      "|   372| 177593| 4.2397866|  null|\n",
      "|   530|  25906| 4.6744313|  null|\n",
      "|   596| 171495| 4.4235716|  null|\n",
      "|   604| 134796|  4.806554|  null|\n",
      "|   122| 170355|  5.929523|  null|\n",
      "|   193|  89904| 4.4845576|  null|\n",
      "|   321| 117531| 4.5056376|  null|\n",
      "|   358| 170355| 4.5756516|  null|\n",
      "|   451|   5915|  4.921042|  null|\n",
      "|   481| 170355|  3.910033|  null|\n",
      "|   545|   3379|  4.792139|  null|\n",
      "|    20|   3379| 4.9206986|  null|\n",
      "|    93|   7842|  5.554637|  null|\n",
      "+------+-------+----------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Left join to get the movies which have not been reviewed\n",
    "finalRecs = finalRecommendations.join(movie_ratings,['userId','movieId'],'left') \\\n",
    "                                .filter(movie_ratings.rating.isNull())\n",
    "finalRecs.createOrReplaceTempView(\"final_Recommendations\")\n",
    "spark.sql(\"SELECT * FROM final_Recommendations limit 20\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4ab577aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalRecs.registerTempTable(\"final_Recommendations\")\n",
    "movies_df.registerTempTable(\"movies_df\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac91b0c",
   "metadata": {},
   "source": [
    "### Recommending Movies to certain users\n",
    "\n",
    "User IDs to recommend:\n",
    "\n",
    "userID = 37\n",
    "\n",
    "userID = 436"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "79984753",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|userID|\n",
      "+------+\n",
      "|   471|\n",
      "|   496|\n",
      "|   148|\n",
      "|   463|\n",
      "|   243|\n",
      "|   540|\n",
      "|   392|\n",
      "|    31|\n",
      "|   516|\n",
      "|   137|\n",
      "|   451|\n",
      "|   251|\n",
      "|   580|\n",
      "|    85|\n",
      "|    65|\n",
      "|   458|\n",
      "|   481|\n",
      "|   588|\n",
      "|   255|\n",
      "|    53|\n",
      "|   133|\n",
      "|   296|\n",
      "|   472|\n",
      "|   322|\n",
      "|   513|\n",
      "|    78|\n",
      "|   321|\n",
      "|   362|\n",
      "|   597|\n",
      "|   593|\n",
      "|   375|\n",
      "|   108|\n",
      "|   155|\n",
      "|   530|\n",
      "|   193|\n",
      "|   368|\n",
      "|    34|\n",
      "|   211|\n",
      "|   101|\n",
      "|   115|\n",
      "|   126|\n",
      "|   385|\n",
      "|    81|\n",
      "|   183|\n",
      "|   210|\n",
      "|   436|\n",
      "|    28|\n",
      "|   596|\n",
      "|   497|\n",
      "|   412|\n",
      "|   300|\n",
      "|   406|\n",
      "|   587|\n",
      "|    76|\n",
      "|   577|\n",
      "|    27|\n",
      "|   332|\n",
      "|    26|\n",
      "|   501|\n",
      "|   384|\n",
      "|   606|\n",
      "|   192|\n",
      "|    44|\n",
      "|   271|\n",
      "|   159|\n",
      "|   253|\n",
      "|   460|\n",
      "|   236|\n",
      "|   329|\n",
      "|   103|\n",
      "|   350|\n",
      "|   336|\n",
      "|    12|\n",
      "|   223|\n",
      "|   602|\n",
      "|   417|\n",
      "|   548|\n",
      "|   388|\n",
      "|   578|\n",
      "|    91|\n",
      "|   409|\n",
      "|   333|\n",
      "|   285|\n",
      "|   601|\n",
      "|   222|\n",
      "|   372|\n",
      "|   604|\n",
      "|   330|\n",
      "|   128|\n",
      "|   209|\n",
      "|    22|\n",
      "|   122|\n",
      "|   493|\n",
      "|   230|\n",
      "|   319|\n",
      "|    93|\n",
      "|   157|\n",
      "|   225|\n",
      "|   232|\n",
      "|   233|\n",
      "|   190|\n",
      "|   367|\n",
      "|   539|\n",
      "|   346|\n",
      "|   246|\n",
      "|   476|\n",
      "|   360|\n",
      "|   599|\n",
      "|   224|\n",
      "|   519|\n",
      "|   111|\n",
      "|    47|\n",
      "|   556|\n",
      "|   140|\n",
      "|   416|\n",
      "|   177|\n",
      "|   132|\n",
      "|   152|\n",
      "|   444|\n",
      "|   353|\n",
      "|   185|\n",
      "|   355|\n",
      "|   305|\n",
      "|   291|\n",
      "|   325|\n",
      "|   386|\n",
      "|   473|\n",
      "|   435|\n",
      "|   581|\n",
      "|   146|\n",
      "|   512|\n",
      "|   259|\n",
      "|     1|\n",
      "|   206|\n",
      "|   297|\n",
      "|   363|\n",
      "|    52|\n",
      "|   212|\n",
      "|   274|\n",
      "|   442|\n",
      "|   182|\n",
      "|   218|\n",
      "|    13|\n",
      "|   440|\n",
      "|   280|\n",
      "|   348|\n",
      "|    16|\n",
      "|    86|\n",
      "|     6|\n",
      "|   474|\n",
      "|   168|\n",
      "|   572|\n",
      "|   205|\n",
      "|   178|\n",
      "|   142|\n",
      "|     3|\n",
      "|   328|\n",
      "|   308|\n",
      "|    20|\n",
      "|    40|\n",
      "|   429|\n",
      "|   470|\n",
      "|   164|\n",
      "|   169|\n",
      "|   500|\n",
      "|   359|\n",
      "|   283|\n",
      "|   139|\n",
      "|   479|\n",
      "|   431|\n",
      "|   340|\n",
      "|   295|\n",
      "|   402|\n",
      "|   432|\n",
      "|   377|\n",
      "|   582|\n",
      "|    94|\n",
      "|   250|\n",
      "|    57|\n",
      "|   570|\n",
      "|   292|\n",
      "|   306|\n",
      "|   339|\n",
      "|   120|\n",
      "|    54|\n",
      "|   559|\n",
      "|   491|\n",
      "|   545|\n",
      "|   235|\n",
      "|    96|\n",
      "|   452|\n",
      "|   266|\n",
      "|   507|\n",
      "|   544|\n",
      "|    48|\n",
      "|   163|\n",
      "|   191|\n",
      "|   268|\n",
      "|     5|\n",
      "|   258|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT DISTINCT(userID) FROM final_Recommendations limit 200\").show(n=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6361cb9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 13288:======>      (15 + 8) / 32][Stage 13289:>              (0 + 0) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|userId|               title|\n",
      "+------+--------------------+\n",
      "|    37|  The Big Bus (1976)|\n",
      "|    37|Mulholland Dr. (1...|\n",
      "|    37| On the Beach (1959)|\n",
      "|    37|         Seve (2014)|\n",
      "|    37|Dragon Ball Z: Th...|\n",
      "|    37|    Jetée, La (1962)|\n",
      "|    37|              Cosmos|\n",
      "|    37|         Dune (2000)|\n",
      "|    37|  Saving Face (2004)|\n",
      "|    37|Man Bites Dog (C'...|\n",
      "+------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT userId, title \\\n",
    "            FROM final_Recommendations t1 \\\n",
    "            LEFT JOIN movies_df t2 \\\n",
    "            ON t1.movieId = t2.movieId \\\n",
    "            WHERE t1.userId=37 LIMIT 10\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2438bba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 13473:(98 + 2) / 100][Stage 13474:(0 + 6) / 32][Stage 13475:>(0 + 0) / 1]\r",
      "\r",
      "[Stage 13474:====>        (11 + 8) / 32][Stage 13475:>              (0 + 0) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|userId|               title|\n",
      "+------+--------------------+\n",
      "|   436|        Thief (1981)|\n",
      "|   436|Hello, Dolly! (1969)|\n",
      "|   436|  The Big Bus (1976)|\n",
      "|   436|Mulholland Dr. (1...|\n",
      "|   436| On the Beach (1959)|\n",
      "|   436|         Seve (2014)|\n",
      "|   436|Dragon Ball Z: Th...|\n",
      "|   436|Babes in Toyland ...|\n",
      "|   436|  Saving Face (2004)|\n",
      "|   436|Shall We Dance (1...|\n",
      "+------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 13475:>                                                      (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT userId, title \\\n",
    "            FROM final_Recommendations t1 \\\n",
    "            LEFT JOIN movies_df t2 \\\n",
    "            ON t1.movieId = t2.movieId \\\n",
    "            WHERE t1.userId=436 \\\n",
    "            LIMIT 10\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
