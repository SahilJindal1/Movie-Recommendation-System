{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "%matplotlib inline\n",
    "\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import col, mean, udf, lit, current_timestamp, unix_timestamp, array_contains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Data to RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/19 18:19:00 WARN Utils: Your hostname, sahil-dell resolves to a loopback address: 127.0.1.1; using 192.168.0.13 instead (on interface wlp2s0)\n",
      "22/11/19 18:19:00 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/19 18:19:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"moive recommender\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = spark.read.load(\"/home/sahil/Desktop/Fall 22/CS 532/project/ml-latest/movies.csv\", format='csv', header = True)\n",
    "ratings_df = spark.read.load(\"/home/sahil/Desktop/Fall 22/CS 532/project/ml-latest/ratings.csv\", format='csv', header = True)\n",
    "links_df = spark.read.load(\"/home/sahil/Desktop/Fall 22/CS 532/project/ml-latest/links.csv\", format='csv', header = True)\n",
    "tags_df = spark.read.load(\"/home/sahil/Desktop/Fall 22/CS 532/project/ml-latest/tags.csv\", format='csv', header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(movies_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the dataframes and make the lifetime of dataframes sames as spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+\n",
      "|movieId|               title|              genres|\n",
      "+-------+--------------------+--------------------+\n",
      "|      1|    Toy Story (1995)|Adventure|Animati...|\n",
      "|      2|      Jumanji (1995)|Adventure|Childre...|\n",
      "|      3|Grumpier Old Men ...|      Comedy|Romance|\n",
      "|      4|Waiting to Exhale...|Comedy|Drama|Romance|\n",
      "|      5|Father of the Bri...|              Comedy|\n",
      "+-------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[movieId: string, title: string, genres: string]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "movies_df.show(5)\n",
    "\n",
    "movies_df.createOrReplaceTempView(\"movies_df\")\n",
    "\n",
    "display (spark.sql(\"SELECT * FROM movies_df limit 5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating| timestamp|\n",
      "+------+-------+------+----------+\n",
      "|     1|    307|   3.5|1256677221|\n",
      "|     1|    481|   3.5|1256677456|\n",
      "|     1|   1091|   1.5|1256677471|\n",
      "|     1|   1257|   4.5|1256677460|\n",
      "|     1|   1449|   4.5|1256677264|\n",
      "+------+-------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[userId: string, movieId: string, rating: string, timestamp: string]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ratings_df.show(5)\n",
    "ratings_df.createOrReplaceTempView(\"ratings_df\")\n",
    "display (spark.sql(\"SELECT * FROM ratings_df limit 5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+\n",
      "|movieId| imdbId|tmdbId|\n",
      "+-------+-------+------+\n",
      "|      1|0114709|   862|\n",
      "|      2|0113497|  8844|\n",
      "|      3|0113228| 15602|\n",
      "|      4|0114885| 31357|\n",
      "|      5|0113041| 11862|\n",
      "+-------+-------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[movieId: string, imdbId: string, tmdbId: string]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "links_df.show(5)\n",
    "\n",
    "links_df.createOrReplaceTempView(\"links_df\")\n",
    "\n",
    "display (spark.sql(\"SELECT * FROM links_df limit 5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------------+----------+\n",
      "|userId|movieId|         tag| timestamp|\n",
      "+------+-------+------------+----------+\n",
      "|    14|    110|        epic|1443148538|\n",
      "|    14|    110|    Medieval|1443148532|\n",
      "|    14|    260|      sci-fi|1442169410|\n",
      "|    14|    260|space action|1442169421|\n",
      "|    14|    318|imdb top 250|1442615195|\n",
      "+------+-------+------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[userId: string, movieId: string, tag: string, timestamp: string]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tags_df.show(5)\n",
    "\n",
    "tags_df.createOrReplaceTempView(\"tags_df\")\n",
    "\n",
    "display (spark.sql(\"SELECT * FROM tags_df limit 5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Registering the dataframes to spark "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sahil/.local/lib/python3.10/site-packages/pyspark/sql/dataframe.py:229: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "movies_df.registerTempTable(\"movies\")\n",
    "ratings_df.registerTempTable(\"ratings\")\n",
    "links_df.registerTempTable(\"links\")\n",
    "tags_df.registerTempTable(\"tags\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum number of ratings per user: 1\n",
      "Minimum number of ratings per movie: 1\n"
     ]
    }
   ],
   "source": [
    "minRating_1 = ratings_df.groupBy(\"userID\").count().toPandas()['count'].min()\n",
    "minRating_2 = ratings_df.groupBy(\"movieId\").count().toPandas()['count'].min()\n",
    "\n",
    "print('Minimum number of ratings per user: {}'.format(minRating_1))\n",
    "print('Minimum number of ratings per movie: {}'.format(minRating_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 17:================================================>         (5 + 1) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movies are rated by only one user: 10155 out of 53889 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "_rating1 = sum(ratings_df.groupBy(\"movieId\").count().toPandas()['count'] == 1)\n",
    "_total = ratings_df.select('movieId').distinct().count()\n",
    "\n",
    "print('movies are rated by only one user: {} out of {} '.format(_rating1, _total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[num_users: bigint]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "283228"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of distinct users\n",
    "num_users = spark.sql(\"SELECT count (distinct userID) as num_users FROM ratings\")\n",
    "display(num_users)\n",
    "ratings_df.select(\"userId\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[num_movies: bigint]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "58098"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of movies\n",
    "num_movies = spark.sql(\"SELECT count (distinct movieID) as num_movies FROM movies\")\n",
    "display(num_movies)\n",
    "movies_df.select('movieID').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 35:================================================>         (5 + 1) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many movies are rated by users? 53889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "rated_by_users = ratings_df.select('movieID').distinct().count()\n",
    "print('How many movies are rated by users?', rated_by_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 45:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------+\n",
      "|               title|              genres|rating|\n",
      "+--------------------+--------------------+------+\n",
      "|   Fambul Tok (2011)|         Documentary|  null|\n",
      "|Shadow Boxers (1999)|         Documentary|  null|\n",
      "| 9500 Liberty (2009)|         Documentary|  null|\n",
      "|  Ascent, The (1994)|       Adventure|War|  null|\n",
      "|Laffghanistan: Co...|Comedy|Documentar...|  null|\n",
      "|      Annie O (1996)|       Drama|Romance|  null|\n",
      "|Cry in the Night,...|      Drama|Thriller|  null|\n",
      "|Across the Sierra...|Action|Romance|We...|  null|\n",
      "|Bachelor Bait (1934)|      Comedy|Romance|  null|\n",
      "|Back in the Saddl...|Action|Drama|Western|  null|\n",
      "+--------------------+--------------------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# null rated movies\n",
    "spark.sql(\"SELECT movies.title, movies.genres ,ratings.rating FROM movies left JOIN ratings ON ratings.movieId = movies.movieID WHERE ratings.rating IS null LIMIT 10\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 46:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|              genres|\n",
      "+--------------------+\n",
      "|Comedy|Horror|Thr...|\n",
      "|Adventure|Sci-Fi|...|\n",
      "|Action|Adventure|...|\n",
      "| Action|Drama|Horror|\n",
      "|Comedy|Drama|Horr...|\n",
      "|Action|Animation|...|\n",
      "|Fantasy|Musical|M...|\n",
      "|Adventure|Mystery...|\n",
      "|Children|Comedy|D...|\n",
      "|Action|Adventure|...|\n",
      "+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# all movie genres\n",
    "spark.sql(\"SELECT DISTINCT(genres) FROM movies LIMIT 10\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[movieId: string, title: string, genres: array<string>]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "extract_genres = udf(lambda x: x.split(\"|\"), ArrayType(StringType()))\n",
    "movies_df_clean = movies_df.select(\"movieId\", \"title\", extract_genres(\"genres\").alias(\"genres\"))\n",
    "\n",
    "movies_df_clean.createOrReplaceTempView(\"movies_df_clean\")\n",
    "\n",
    "display (spark.sql(\"SELECT * FROM movies_df_clean limit 5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 49:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+\n",
      "|movieId|               title|              genres|\n",
      "+-------+--------------------+--------------------+\n",
      "|      1|    Toy Story (1995)|[Adventure, Anima...|\n",
      "|      2|      Jumanji (1995)|[Adventure, Child...|\n",
      "|      3|Grumpier Old Men ...|   [Comedy, Romance]|\n",
      "|      4|Waiting to Exhale...|[Comedy, Drama, R...|\n",
      "|      5|Father of the Bri...|            [Comedy]|\n",
      "+-------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "movies_df_clean.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Western',\n",
       " 'IMAX',\n",
       " 'Crime',\n",
       " 'Film-Noir',\n",
       " 'Comedy',\n",
       " 'Action',\n",
       " 'Fantasy',\n",
       " 'Drama',\n",
       " 'Sci-Fi',\n",
       " 'Mystery',\n",
       " 'Musical',\n",
       " 'Children',\n",
       " '(no genres listed)',\n",
       " 'War',\n",
       " 'Documentary',\n",
       " 'Horror',\n",
       " 'Adventure',\n",
       " 'Animation',\n",
       " 'Romance',\n",
       " 'Thriller']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All movie categories\n",
    "genres_result = list(set(movies_df_clean.select('genres').rdd.flatMap(tuple).flatMap(tuple).collect()))\n",
    "genres_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_pdf = movies_df.toPandas()\n",
    "list_of_movie = list(movie_pdf['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_ratings=ratings_df.drop('timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data type convert\n",
    "from pyspark.sql.types import IntegerType, FloatType\n",
    "movie_ratings = movie_ratings.withColumn(\"userId\", movie_ratings[\"userId\"].cast(IntegerType()))\n",
    "movie_ratings = movie_ratings.withColumn(\"movieId\", movie_ratings[\"movieId\"].cast(IntegerType()))\n",
    "movie_ratings = movie_ratings.withColumn(\"rating\", movie_ratings[\"rating\"].cast(FloatType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+\n",
      "|userId|movieId|rating|\n",
      "+------+-------+------+\n",
      "|     1|    307|   3.5|\n",
      "|     1|    481|   3.5|\n",
      "|     1|   1091|   1.5|\n",
      "|     1|   1257|   4.5|\n",
      "|     1|   1449|   4.5|\n",
      "|     1|   1590|   2.5|\n",
      "|     1|   1591|   1.5|\n",
      "|     1|   2134|   4.5|\n",
      "|     1|   2478|   4.0|\n",
      "|     1|   2840|   3.0|\n",
      "+------+-------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[userId: int, movieId: int, rating: float]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "movie_ratings.show(10)\n",
    "movie_ratings.createOrReplaceTempView(\"movie_ratings\")\n",
    "display (spark.sql(\"SELECT * FROM movie_ratings limit 10\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "name": "Movie Recommendation Engine in Apache Spark",
  "notebookId": 2964997303881322
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
